{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGaJWgkGPO8k",
        "outputId": "571c502f-8162-4e0d-b381-3425fd7e449d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317130 sha256=8a1c2829f7269bdd24dadd60c74bd6d882d880a5066dda52df5ae69702dcd86e\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.0\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *"
      ],
      "metadata": {
        "id": "zMjSzfBFPUut"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup da aplicação Spark\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"job-glue-spark-tvnews\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "yyfOkv4cPVE0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# definindo o método de logging da aplicação use INFO somente para DEV [INFO,ERROR]\n",
        "spark.sparkContext.setLogLevel(\"ERROR\")"
      ],
      "metadata": {
        "id": "5G5NaBoTPVaX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_mat = spark.read.format(\"csv\")\\\n",
        "    .option(\"header\", \"True\")\\\n",
        "    .option(\"inferSchema\",\"True\")\\\n",
        "    .csv(\"/content/drive/MyDrive/Dados/Tvnews/landing/materia.csv\")\n",
        "df_usu = spark.read.format(\"csv\")\\\n",
        "    .option(\"header\", \"True\")\\\n",
        "    .option(\"inferSchema\",\"True\")\\\n",
        "    .csv(\"/content/drive/MyDrive/Dados/Tvnews/landing/usuarios.csv\")\n",
        "df_edi = spark.read.format(\"csv\")\\\n",
        "    .option(\"header\", \"True\")\\\n",
        "    .option(\"inferSchema\",\"True\")\\\n",
        "    .csv(\"/content/drive/MyDrive/Dados/Tvnews/landing/editoria.csv\")\n",
        "df_muni = spark.read.format(\"csv\")\\\n",
        "    .option(\"header\", \"True\")\\\n",
        "    .option(\"inferSchema\",\"True\")\\\n",
        "    .csv(\"/content/drive/MyDrive/Dados/Tvnews/landing/municipio.csv\")\n",
        "df_tpmat = spark.read.format(\"csv\")\\\n",
        "    .option(\"header\", \"True\")\\\n",
        "    .option(\"inferSchema\",\"True\")\\\n",
        "    .csv(\"/content/drive/MyDrive/Dados/Tvnews/landing/tipomateria.csv\")"
      ],
      "metadata": {
        "id": "dwdtU5nHPWZD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imprime os dados lidos da raw\n",
        "print (\"\\nImprime os dados lidos da landing:\")\n",
        "\n",
        "# imprime o schema do dataframe\n",
        "print (\"\\nImprime o schema do dataframe lido da landing:\")"
      ],
      "metadata": {
        "id": "IawK3QRlPYhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converte para formato parquet\n",
        "print (\"\\nEscrevendo os dados lidos da raw para parquet na processing zone...\")\n",
        "df_mat.write.format(\"parquet\")\\\n",
        "        .mode(\"overwrite\")\\\n",
        "        .save(\"/content/drive/MyDrive/Dados/Tvnews/processing2/dbo_materia.parquet\")\n",
        "df_usu.write.format(\"parquet\")\\\n",
        "        .mode(\"overwrite\")\\\n",
        "        .save(\"/content/drive/MyDrive/Dados/Tvnews/processing2/dbo_usuario.parquet\")\n",
        "df_edi.write.format(\"parquet\")\\\n",
        "        .mode(\"overwrite\")\\\n",
        "        .save(\"/content/drive/MyDrive/Dados/Tvnews/processing2/dbo_editoria.parquet\")\n",
        "df_muni.write.format(\"parquet\")\\\n",
        "        .mode(\"overwrite\")\\\n",
        "        .save(\"/content/drive/MyDrive/Dados/Tvnews/processing2/dbo_municipio.parquet\")\n",
        "df_tpmat.write.format(\"parquet\")\\\n",
        "        .mode(\"overwrite\")\\\n",
        "        .save(\"/content/drive/MyDrive/Dados/Tvnews/processing2/dob_tipomateria.parquet\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vi-huDIVPYzJ",
        "outputId": "752cda58-ea43-4b15-c32d-a22565c8d9e4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Escrevendo os dados lidos da raw para parquet na processing zone...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lendo arquivos parquet\n",
        "df_mat_parquet = spark.read.format(\"parquet\")\\\n",
        " .load(\"/content/drive/MyDrive/Dados/Tvnews/processing2/dbo_materia.parquet/*.parquet\")\n",
        "df_usu_parquet = spark.read.format(\"parquet\")\\\n",
        " .load(\"/content/drive/MyDrive/Dados/Tvnews/processing2/dbo_usuario.parquet/*.parquet\")\n",
        "df_edi_parquet = spark.read.format(\"parquet\")\\\n",
        " .load(\"/content/drive/MyDrive/Dados/Tvnews/processing2/dbo_editoria.parquet/*.parquet\")\n",
        "df_muni_parquet = spark.read.format(\"parquet\")\\\n",
        " .load(\"/content/drive/MyDrive/Dados/Tvnews/processing2/dbo_municipio.parquet/*.parquet\")\n",
        "df_tpmat_parquet = spark.read.format(\"parquet\")\\\n",
        " .load(\"/content/drive/MyDrive/Dados/Tvnews/processing2/dob_tipomateria.parquet/*.parquet\")"
      ],
      "metadata": {
        "id": "kjQInUd_QxZH"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_mat_count = df_mat_parquet.select('CODMATERIA')\n",
        "df_mat_count.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wohprtbVz04",
        "outputId": "cb85b22c-7f94-4b65-a5c5-bba292f8f874"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "116158"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Selecionando apenas as colunas necessarias dos dataframes\n",
        "df_usu_parquet = df_usu_parquet.select('CODUSUARIO', 'US_NOME')\n",
        "df_muni_parquet = df_muni_parquet.select('CODMUNICIPIO', 'MU_NOME')\n",
        "df_edi_parquet = df_edi_parquet.select('CODEDITORIA', 'ED_DESCRICAO')\n",
        "df_tpmat_parquet = df_tpmat_parquet.select('CODTIPOMATERIA', 'TM_DESCRICAO')"
      ],
      "metadata": {
        "id": "FB_a7hq4Qxwx"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Substituindo o codigo dos reportes, produtores, cinegrafistas pelo nome\n",
        "df_joined = df_mat_parquet.join(df_usu_parquet, df_mat_parquet.CODREPORTER == df_usu_parquet.CODUSUARIO, 'left').withColumnRenamed('US_NOME', 'REPORTER').withColumnRenamed('CODUSUARIO', 'CODREPORTER_')\n",
        "df_joined = df_joined.join(df_usu_parquet, df_mat_parquet.CODPRODUTOR == df_usu_parquet.CODUSUARIO, 'left').withColumnRenamed('US_NOME', 'PRODUTOR').withColumnRenamed('CODUSUARIO', 'CODPRODUTOR_')\n",
        "df_joined = df_joined.join(df_usu_parquet, df_mat_parquet.CODCINEGRAFISTA == df_usu_parquet.CODUSUARIO, 'left').withColumnRenamed('US_NOME', 'CINEGRAFISTA').withColumnRenamed('CODUSUARIO', 'CODPRODUTOR_')\n"
      ],
      "metadata": {
        "id": "QitAHmg0QyE7"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Substituindo o codigo dos municipios, editoria, tipo da materia por seus respectivos nomes\n",
        "df_joined = df_joined.join(df_muni_parquet, df_mat_parquet.CODMUNICIPIO == df_muni_parquet.CODMUNICIPIO, 'left').withColumnRenamed('MU_NOME', 'MUNICIPIO').withColumnRenamed('CODMUNICIPIO', 'CODREPORTER_')\\\n",
        "                     .join(df_edi_parquet, df_mat_parquet.CODEDITORIA == df_edi_parquet.CODEDITORIA, 'left').withColumnRenamed('ED_DESCRICAO', 'EDITORIA').withColumnRenamed('CODEDITORIA', 'CODEDITORIA_')\\\n",
        "                     .join(df_tpmat_parquet, df_mat_parquet.CODTIPOMATERIA == df_tpmat_parquet.CODTIPOMATERIA, 'left').withColumnRenamed('TM_DESCRICAO', 'TIPO_MATERIA').withColumnRenamed('CODTIPOMATERIA', 'CODTIPOMATERIA_')\n"
      ],
      "metadata": {
        "id": "1pEPH5P2RSXs"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_soft = df_joined.select('CODMATERIA', 'PRODUTOR','REPORTER','CINEGRAFISTA','MUNICIPIO','TIPO_MATERIA','EDITORIA','MA_DATA','MA_LOCAL','MA_RETRANCA')"
      ],
      "metadata": {
        "id": "hoPH2Jy2RSqb"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_soft = df_soft.withColumn(\"MA_LOCAL\", when(col(\"MA_LOCAL\") == 'POLÍCIA', 'DELEGACIA').otherwise(col(\"MA_LOCAL\")))\\\n",
        "                   .withColumn(\"MA_LOCAL\", when(col(\"MA_LOCAL\") == 'POLICIA', 'DELEGACIA').otherwise(col(\"MA_LOCAL\")))\\\n",
        "                   .withColumn(\"MA_LOCAL\", when(col(\"MA_LOCAL\") == 'ESTÁDIO BARBALHÃO', 'ESTÁDIO COLOSSO DO TAPAJÓS').otherwise(col(\"MA_LOCAL\")))\\\n",
        "                   .withColumn(\"MA_LOCAL\", when(col(\"MA_LOCAL\") == 'COLOSSO DO TAPAJÓS', 'ESTÁDIO COLOSSO DO TAPAJÓS').otherwise(col(\"MA_LOCAL\")))\\\n",
        "                   .withColumn(\"MA_LOCAL\", when(col(\"MA_LOCAL\") == 'CÂMARA', 'CÂMARA DE VEREADORES').otherwise(col(\"MA_LOCAL\")))"
      ],
      "metadata": {
        "id": "w3W8JlMqRS42"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Limpeza na coluna MA_LOCAL\n",
        "df_final = df_soft.withColumn('MA_LOCAL', when(col('MA_LOCAL').rlike('X{2,}'), 'NAO ESPECIFICADO').otherwise(col('MA_LOCAL')))\\\n",
        "                               .withColumn('MA_LOCAL', when(col('MA_LOCAL').rlike('\\.{2,}'), 'NAO ESPECIFICADO').otherwise(col('MA_LOCAL')))\\\n",
        "                               .withColumn('MA_LOCAL', when(col('MA_LOCAL').rlike('\\,{2,}'), 'NAO ESPECIFICADO').otherwise(col('MA_LOCAL')))\\\n",
        "                               .withColumn('MA_LOCAL', when(col('MA_LOCAL').rlike('\\\\*,{2,}'), 'NAO ESPECIFICADO').otherwise(col('MA_LOCAL')))\\\n",
        "                               .withColumn('MA_LOCAL', when(col('MA_LOCAL').rlike('Z{2,}'), 'NAO ESPECIFICADO').otherwise(col('MA_LOCAL')))\\\n",
        "                               .withColumn('MA_LOCAL', when(col('MA_LOCAL').rlike('\\;{2,}'), 'NAO ESPECIFICADO').otherwise(col('MA_LOCAL')))\\\n",
        "                               .withColumn('MA_LOCAL', when(col('MA_LOCAL').rlike('-{2,}'), 'NAO ESPECIFICADO').otherwise(col('MA_LOCAL')))"
      ],
      "metadata": {
        "id": "DLEv5DJ2RoFl"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crie uma lista das palavras que você deseja substituir\n",
        "palavras_para_substituir = [ 'NA PAURTA',r'\\bS\\b',r'\\bN PAUTA\\b',r'\\b-\\b','NA PAUTA', r'\\b//\\b','NA PAUTA//','SANTARÉM','SANTAREM','TV','STM','VÁRIOS','///','/','VER PAUTA','VER PAUTA','INDEFINIDO',r'\\bRUA\\b','VER NA PAUTA','RUAS','A DEFINIR','\\\\.', r'\\b;\\b', r'\\bVÍDEO\\b','\\\\*+',r'\\bR\\b',r'\\bRR\\b','RRR','SSSS',r'\\bD\\b','AAA',r'\\bAA\\b','////','SSS',r'\\bSS\\b',r'\\bQ\\b',r'\\bVARIOS\\b','LLLL','NA ´PAUTA','N APAUTA','NA OPAUTA','GGG','NA PAUTAS']  # note que estamos escapando o ponto\n",
        "\n",
        "# Crie a expressão regular\n",
        "regex = '|'.join(palavras_para_substituir)\n",
        "\n",
        "# Substitua a coluna se ela contiver qualquer uma das palavras na lista\n",
        "df_final = df_final.withColumn('MA_LOCAL', when(col('MA_LOCAL').rlike(regex), 'NAO ESPECIFICADO').otherwise(col('MA_LOCAL')))"
      ],
      "metadata": {
        "id": "h3vLeIDsRrIk"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final.show(truncate=False)"
      ],
      "metadata": {
        "id": "Z7KU943FR40l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final.repartition(1)\\\n",
        "          .write\\\n",
        "          .format(\"parquet\")\\\n",
        "          .mode(\"overwrite\")\\\n",
        "          .save(\"/content/drive/MyDrive/Dados/Tvnews/curated2/tvnews-full.parquet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6BxO9HUVu-g",
        "outputId": "fd18ba89-395f-433c-b1e3-78b8827ad7a5"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "116158"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    }
  ]
}